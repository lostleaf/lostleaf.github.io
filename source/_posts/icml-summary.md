---
title: ICML参会小结
date: 2014-07-09 14:22
tags:
- Machine Learning
- Conference
categories:
- Misc
---

今年(2014年)的国际机器学习大会（ICML）已经基本结束了，在新的时代里，机器学习也有了新的变化。

<!--- more --->

## 大数据，新的挑战和机遇

当今互联网时代，越来越多的数据产生了出来，“大数据”、“云”等概念被炒得火热。ICML 作为顶级学术会议，似乎也不能免俗，今年的 tutorial 就有一半与大数据相关。

第一天的会议在 TPAMI 副主编 Max Welling 教授富有吸引力的 Introduction 中拉开了帷幕。 Welling 教授首先介绍了贝叶斯后验推断（Bayesian Posterior Inference）的诸多优点，例如可以量化数据的不确定性以及易于避免过拟合（Overfitting）等，以及该方法在面临大量数据时所遇到的挑战——分析计算比较复杂，特别是在解决复杂问题时或数据量很大的时候，这个问题就尤为突出。

Welling 教授同时也谈到了解决问题的两大途径：

1. 利用分布式系统运行算法
2. 每次迭代只使用一部分数据

此后，Welling 教授具体讲了Variational Bayes 和 MCMC这两种算法的加速方法（比较偏向于如何使用部分数据来加速）。

* 对于 Variational Bayes ，由于每一步需要利用所有数据，复杂度较高，可以使用随机梯度下降（Stochastic Gradient Descent）方法，每次使用随机子集来近似计算梯度来加速。
 
* 对于 MCMC，在经典的 M-H 算法中，由于每一次计算 M-H Test 的复杂度为 O(n)，不太适用于大数据，于是就有两种策略来避免这一问题：使用一种“好的” proposal 方法，从而不需要计算 M-H Test；或者每次使用少量数据去近似 M-H Test。

总体来说，Welling 教授提到的方法中间蕴含的 Idea 大多是传统的机器学习，最优化中就已经存在的 Idea，而现在随着时代发展，这些方法又被结合了起来，焕发出了新的光彩，最近几年过于热门的 Deep Learning 也属于这一类。

第一天下午 Joseph Gonzalez 的讲座则更偏工程一些。Gonzalez 博士是 GraphLab 公司的联合创始人，他们主要致力于使用并行系统高效率地实现机器学习算法，这算是在大数据时代兴起的机器学习与分布式系统交叉产生的新兴研究方向。

Gonzalez 博士以自身经历入手，讲到机器学习算法并行化所面临的种种困境：实现这样一种算法必须同时考虑机器学习方面和大型系统方面的问题，增加了设计以及调试的复杂度；同时由于特定机器学习算法难以扩展，使得机器学习学者需要一遍又一遍地面临同样地系统问题。他认为如果在机器学习和系统之间提供一层很好地抽象，就可以将所有的问题分解为机器学习学者擅长的问题和计算机系统学者擅长的问题。

Gonzalez 博士随后报告了并行学习算法框架的最新进展，其中主要介绍了 Map-Reduce, Spark, Parameter Server, GraphLab, GraphX等框架。其中，后两者是他们自己的产品和研究重点，所以他花了大量的时间来介绍这两个框架与讲解相关测试结果。我做了一下调查，定性地来看他的测试结果，与大部分人的看法还是一致的，同时他也敢于指出自己的东西的缺点，应该来说还比较公正。

## 深度学习持续热门

第一天最后一个 tutorial 来自于 Li Deng 教授，主要为大家回顾了深度学习的历史与进展，被大家称作“深度学习故事会”。Deng 教授首先带领大家回顾了深度学习在最近几年取得的最新成果以及产生的巨大影响。随后，Deng 教授从深度学习在语音方面的应用入手，从语音中堪称经典的高斯混合模型-隐马尔科夫模型，语者适应技术，讲到如今基于深度学习的语音识别，并通过 MSR 在天津的一个自动同声传译的 Demo 向大家展示了深度学习对该领域的巨大影响。之后，Deng 教授也展示了深度学习在计算视觉的影响和在自然语言处理方面以及一些新的挑战——我们需要去创造一套能够对现实世界的复杂事物关系和语义概念等进行 Reasoning 和 Inference 的系统。最后他展示了一个非常 Exciting 的新兴研究方向 Multimodal Processing，同时利用文本和图片/视频数据去学习图片/视频的语义。

Deng 教授说到的一点让我感触很深。一点是深度学习早起在语音识别方面的效果并不比传统方法好太多，当年的 IEEE 审稿人看结果不好直接将论文 reject 掉，但他凭借语音领域的丰富经验，不断优化结果，最后做出了高质量的工作。这告诉我们，做科研要有恒心，不能轻易放弃。

值得提出的是，Google 近年来在深度学习方面投入确实比较大，今年的 ICML 上 Google 发了好几篇深度学习相关的论文。Bengio 的存在感也很强，深度学习 Session 的每个 Talk 他都提出了问题。

## 人和机器

第二天的会议以微软雷德蒙研究院院长 Eric Horvitz 的 Keynote 作为开始。他围绕未来机器被大量数据增强之后，可能更加紧密地辅助人类这一主题，为大家介绍了微软过去几年里在人机互动、人工智能等方面的一些例子。 Horvitz 首先提到了微软将机器学习应用在生物医药信息学和临床医疗等方面。在 MSR，这些成果目前已经应用到其周边的医院，提高了它们的医疗服务水平和决策能力。在他的演讲中，也提到了一些其他的非常惊讶的结果，包括之前天津的实时翻译 Demo 以及 Horvitz 自己办公室里已经投入使用的一套智能化系统的 Demo，这些综合了人工智能方向多个领域的成果让人感觉 AI Dream 又更近了一步。
